# --- GENERAL --- #
cuda_id: 0
notebook: False                                                                  # whether code is run from notebook or not
save_every_step: False                                                           # whether to save every step or not
model_name: 'flex'
bs: 500
# --- PATH: Datasets & Meshes --- #
smplx_dir: './body_utils/body_models'
mano_dir: './body_utils/body_models/mano'
obj_meshes_dir: './dataset/contact_meshes/'
# obj_dir: './dataset/obj/obj_info.npy'
sbj_verts_region_map_pth: './dataset/sbj/sbj_verts_region_mapping.npy'
mano2smplx_verts_ids: './dataset/sbj/MANO_SMPLX_vertex_ids.npy'
interesting_pth: './dataset/sbj/interesting.npz'
sbj_verts_simplified: './dataset/sbj/vertices_simplified_correspondences.npy'
sbj_faces_simplified: './dataset/sbj/faces_simplified.npy'
adj_matrix_orig: './dataset/sbj/adj_matrix_original.npy'
adj_matrix_simplified: './dataset/sbj/adj_matrix_simplified.npy'
# --- TTO --- #
topk: 10                                                                           # how many top results to return
std: -1                                                                           # -1 means random sample, anything else will sample those many SDs away from mean
save_all_meshes: False                                                           # Save all meshes of run.py (should be set to True for debugging only)
alpha_rh_match: 20.0                                                             # factor to weigh right-hand matching loss term
rh_match_type: 'verts'                                                           # joints / verts -- determines matching loss criteria
alpha_interesting_verts: 2.0                                                    # factor to weigh interesting vertices loss term
alpha_lowermost: 0.0                                                            # factor to weigh lowermost loss term
alpha_obstacle_in: 1000.0                                                        # factor to weigh human-obstacle penetration loss term
alpha_obstacle_out: 0.0                                                         # factor to weigh human-obstacle faraway loss term for the (opposite of penetration)
alpha_rh_obstacle_in: 0.0
alpha_rh_obstacle_out:  0.0
alpha_wrist: 0.01
intersection_thresh: 0.005                                                        # threshold for new intersection loss
obstacle_sbj2obj_extra: 'connected_components'                                                        # 'connected_components' / '' (i.e.,none) -- only valid for human, not rhand
obstacle_sbj2obj: True                                                           # whether to have obstacle loss from subject-to-object
obstacle_obj2sbj: False                                                          # whether to have obstacle loss from object-to-subject
alpha_gaze: 0.01                                                                 # factor to weigh human-object gaze loss term
disp_t: True                                                                     # Change translation of object during displacement to test-pose
disp_g: True                                                                     # Change global orientation of object during displacement to test-pose
orient_optim_type: 'ypr'                                                          # How to optimize for global orientationg - either 'ypr' for 'yaw-pitch-roll' or 'aa' for axis-angle
subsample_sbj: True                                                              # Subsample subject vertices for penetration computation speed-up
n_iter: 500                                                                        # Number of iterations of optimization
# --- POSE-GROUND PRIOR --- #
pgprior: True                                                                    # Whether to use pose-prior loss or not (turn off for baseline)
best_pgprior: './pretrained_model/pgp.pth'                                                                  # Path to pretrained pose-ground prior
height: 'transl_z'                                                                # either of 'transl_z' or 'pelvis_z' - depending on what pretrained model is loaded
# --- STAGEWISE TRAINING --- #
num_stagewise: '1'                                                                # Number of optimization iters for different stages
params_stagewise: 'tgpwrh'                                                        # t: transl, g: global orient, p: sbj_pose, w: wrist transl, r: wrist orient, h: hand pose
lrs_stagewise: '5e-2'                                                             # Learning rate for different stages of optimization
# --- LATENT SPACE TRAINING --- #
latent_lr: 0.05                                                                 # Common learning rate for latent-based optimization (Roshi's paper)
lr_mlp_divisor: 10.0                                                            # Learning rate for MLP is divided by this factor
latent_params: 'tgpwrha'
# prediction_scale: {'transl': 10, 'orient': 20, 'w': 0, 'angle': 20}                          # Scale for different parameters in latent space
# gradient_scale: {'transl': 0.3, 'orient': 1, 'w': 0, 'angle': 1}                          # Scale for different gradients in latent space
iteration_filter: [100, 150, 200, 250, 300]
